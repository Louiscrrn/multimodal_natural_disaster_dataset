{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07288c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import cdsapi\n",
    "from pathlib import Path\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef46ae4",
   "metadata": {},
   "source": [
    "# IBTrACS DataSet\n",
    "\n",
    "\n",
    "- We restrict the dataset to time steps where the cyclone position is explicitly reported by the U.S. agency, since spatial localization is required for any subsequent coupling with gridded meteorological data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c5ab44",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(\"data/IBTrACS.ALL.v04r01.nc\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c955377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SID is a unique identifier for a storm in the dataset\n",
    "print(len(ds[\"sid\"].values) == len(set(ds[\"sid\"].values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e0c187",
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = [\n",
    "    \"usa\", \"tokyo\", \"cma\", \"hko\", \"kma\",\n",
    "    \"newdelhi\", \"reunion\", \"bom\",\n",
    "    \"nadi\", \"wellington\"\n",
    "]\n",
    "\n",
    "rows = []\n",
    "\n",
    "for src in sources:\n",
    "    var = f\"{src}_wind\"\n",
    "    if var in ds:\n",
    "        n_storms = int(\n",
    "            ds[var]\n",
    "            .notnull()\n",
    "            .any(dim=\"date_time\")\n",
    "            .sum()\n",
    "            .values\n",
    "        )\n",
    "        rows.append({\n",
    "            \"source\": src,\n",
    "            \"storms_covered\": n_storms\n",
    "        })\n",
    "\n",
    "df_storms = pd.DataFrame(rows).sort_values(\"storms_covered\", ascending=False)\n",
    "\n",
    "# Plot\n",
    "plt.figure()\n",
    "plt.bar(df_storms[\"source\"], df_storms[\"storms_covered\"])\n",
    "plt.xlabel(\"Source\")\n",
    "plt.ylabel(\"Number of storms\")\n",
    "plt.title(\"Storm Coverage\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b674901",
   "metadata": {},
   "source": [
    "Several tropical cyclones are documented by multiple agencies simultaneously; therefore, the sum of per-agency storm counts exceeds the number of unique cyclones.\n",
    "The USA storm coverage is the largest one, therefore it is the one on which we will restrict ourselves during the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f16c7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "\n",
    "# Data Loading\n",
    "ds = xr.open_dataset(\"data/IBTrACS.ALL.v04r01.nc\")\n",
    "\n",
    "print(f\"Number of storms : {len(ds.storm)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338e9398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep relevant variable related to US sources\n",
    "vars_usa = [\n",
    "    \"sid\", \"name\", \"season\", \"basin\",\n",
    "    \"time\",\n",
    "    \"usa_lat\", \"usa_lon\",\n",
    "    \"usa_wind\", \"usa_pres\",\n",
    "    \"storm_speed\", \"storm_dir\"\n",
    "]\n",
    "ds_tc = ds[vars_usa]\n",
    "\n",
    "# Filter when the position (lat, long) is NaN\n",
    "ds_tc_filtered = ds_tc.where(\n",
    "    ds_tc[\"usa_lat\"].notnull()\n",
    "    & ds_tc[\"usa_lon\"].notnull(),\n",
    "    drop=True\n",
    ")\n",
    "\n",
    "# Convert to a pandas DataFrame\n",
    "df_tc_pd = (\n",
    "    ds_tc_filtered\n",
    "    .to_dataframe()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Drop global estimate, the storm index column and rename\n",
    "df_tc_pd = (\n",
    "    df_tc_pd\n",
    "    .drop(columns=[\"storm\", \"lat\", \"lon\"])\n",
    "    .rename(columns={\n",
    "        \"usa_lat\": \"lat\",\n",
    "        \"usa_lon\": \"lon\",\n",
    "        \"usa_wind\": \"wind\",\n",
    "        \"usa_pres\": \"pressure\",\n",
    "        \"time\": \"time_stamp\",\n",
    "    })\n",
    "    .dropna(subset=[\"lat\", \"lon\"])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Conversion in datetime pandas\n",
    "df_tc_pd[\"time_stamp\"] = pd.to_datetime(df_tc_pd[\"time_stamp\"])\n",
    "df_tc_pd[\"year\"] = df_tc_pd[\"time_stamp\"].dt.year\n",
    "df_tc_pd[\"month\"] = df_tc_pd[\"time_stamp\"].dt.month\n",
    "df_tc_pd[\"day\"] = df_tc_pd[\"time_stamp\"].dt.day\n",
    "df_tc_pd[\"hour\"] = df_tc_pd[\"time_stamp\"].dt.hour\n",
    "\n",
    "# Sort by the most recent\n",
    "df = df_tc_pd.sort_values(\n",
    "    by=[\"time_stamp\", \"sid\"],\n",
    "    ascending=[False, True]\n",
    ")\n",
    "\n",
    "\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f752a764",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_per_cyclone = df[\"sid\"].value_counts()\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(obs_per_cyclone.values, bins=10)\n",
    "plt.xlabel(\"Number of observations per cyclone\")\n",
    "plt.ylabel(\"Number of cyclones\")\n",
    "plt.title(\"Histogram of observations per cyclone\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c0b0c5",
   "metadata": {},
   "source": [
    "Some comments on the original acquisition methods of such data.\n",
    "\n",
    "- For all of these they came from estimation based on observation retrieved on-ground, satelite data, drone or planes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd7b825",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df[\n",
    "    (df[\"time_stamp\"].dt.year >= 2000) &\n",
    "    (df[\"time_stamp\"].dt.year < 2025)\n",
    "].copy()\n",
    "\n",
    "print(\n",
    "    \"Période retenue:\",\n",
    "    df_filtered[\"time_stamp\"].dt.year.min(),\n",
    "    \"→\",\n",
    "    df_filtered[\"time_stamp\"].dt.year.max(),\n",
    "    \"| obs:\", len(df_filtered),\n",
    "    \"| cyclones:\", df_filtered[\"sid\"].nunique()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cafc47",
   "metadata": {},
   "source": [
    "# ERA5 DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12befa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_era5_for_row(\n",
    "    row,\n",
    "    out_dir=\"data/era5\",\n",
    "    buffer_deg=5.0,\n",
    "    variables=None,\n",
    "    max_available_time=pd.Timestamp(\"2025-12-10 22:00\"),\n",
    "):\n",
    "    \"\"\"\n",
    "    Download ERA5 single-level data around one IBTrACS observation.\n",
    "    \"\"\"\n",
    "\n",
    "    # Default variables to retrieve\n",
    "    if variables is None:\n",
    "        variables = [\n",
    "            \"mean_sea_level_pressure\",\n",
    "            \"10m_u_component_of_wind\",\n",
    "            \"10m_v_component_of_wind\",\n",
    "            \"2m_temperature\",\n",
    "        ]\n",
    "\n",
    "    # Sanity check for the time\n",
    "    time = pd.to_datetime(row[\"time_stamp\"])\n",
    "    if time > max_available_time:\n",
    "        return None\n",
    "\n",
    "    # Cast Python types\n",
    "    lat = float(row[\"lat\"])\n",
    "    lon = float(row[\"lon\"])\n",
    "    year = int(time.year)\n",
    "    month = int(time.month)\n",
    "    day = int(time.day)\n",
    "    hour = int(time.hour)\n",
    "\n",
    "    # Directory and file name\n",
    "    out_dir = Path(out_dir)\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    fname = (\n",
    "        f\"era5_{row['sid'].decode() if isinstance(row['sid'], bytes) else row['sid']}_\"\n",
    "        f\"{year}{month:02d}{day:02d}_{hour:02d}.nc\"\n",
    "    )\n",
    "    out_path = out_dir / fname\n",
    "\n",
    "    # Cache\n",
    "    if out_path.exists():\n",
    "        return out_path\n",
    "\n",
    "    # Request ERA5\n",
    "    c = cdsapi.Client()\n",
    "\n",
    "    dataset = \"reanalysis-era5-single-levels\"\n",
    "    request = {\n",
    "        \"product_type\": [\"reanalysis\"],\n",
    "        \"variable\": [\n",
    "            \"10m_u_component_of_wind\",\n",
    "            \"10m_v_component_of_wind\",\n",
    "            \"2m_temperature\",\n",
    "            \"mean_sea_level_pressure\"\n",
    "        ],\n",
    "        \"year\": [\"2017\"],\n",
    "        \"month\": [\"10\"],\n",
    "        \"day\": [\"23\", \"24\", \"25\"],\n",
    "        \"time\": [\n",
    "            \"00:00\", \"01:00\", \"02:00\",\n",
    "            \"03:00\", \"04:00\", \"05:00\",\n",
    "            \"06:00\", \"07:00\", \"08:00\",\n",
    "            \"09:00\", \"10:00\", \"11:00\",\n",
    "            \"12:00\", \"13:00\", \"14:00\",\n",
    "            \"15:00\", \"16:00\", \"17:00\",\n",
    "            \"18:00\", \"19:00\", \"20:00\",\n",
    "            \"21:00\", \"22:00\", \"23:00\"\n",
    "        ],\n",
    "        \"format\": \"netcdf\",\n",
    "        \"area\": [\n",
    "            30, \n",
    "            -80, \n",
    "            10, \n",
    "            -60\n",
    "            ]\n",
    "    }\n",
    "\n",
    "    c.retrieve(dataset, request, str(out_path))\n",
    "\n",
    "    return out_path\n",
    "\n",
    "\n",
    "def extract_era5_at_point(ds_era5, lat, lon):\n",
    "    ds_point = ds_era5.sel(\n",
    "        latitude=lat,\n",
    "        longitude=lon,\n",
    "        method=\"nearest\"\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"era5_msl\": ds_point[\"msl\"].values.item() / 100.0, \n",
    "        \"era5_u10\": ds_point[\"u10\"].values.item(),\n",
    "        \"era5_v10\": ds_point[\"v10\"].values.item(),\n",
    "        \"era5_t2m\": ds_point[\"t2m\"].values.item(),\n",
    "    }\n",
    "\n",
    "\n",
    "def build_enriched_row(row, era5_features):\n",
    "    \"\"\"\n",
    "    Combine a row from IBTrACS and ERA5 features in a single pandas row.\n",
    "    \"\"\"\n",
    "    base = row.copy()\n",
    "\n",
    "    for col in [\"sid\", \"name\", \"basin\"]:\n",
    "        if col in base and isinstance(base[col], bytes):\n",
    "            base[col] = base[col].decode()\n",
    "\n",
    "    for k, v in era5_features.items():\n",
    "        base[k] = v\n",
    "\n",
    "    return pd.DataFrame([base])\n",
    "\n",
    "\n",
    "\n",
    "def enrich_ibtracs_with_era5(\n",
    "    df,\n",
    "    max_rows=None,\n",
    "    drop_failed=True,\n",
    "    verbose=True,\n",
    "    throttle_seconds=2.0, \n",
    "):\n",
    "    \"\"\"\n",
    "    Loop on rows of IBTrACS\n",
    "    \"\"\"\n",
    "\n",
    "    enriched_rows = []\n",
    "\n",
    "    iterable = df.itertuples(index=False)\n",
    "    if max_rows is not None:\n",
    "        iterable = list(iterable)[:max_rows]\n",
    "\n",
    "    for i, row in enumerate(iterable):\n",
    "        row = pd.Series(row._asdict())\n",
    "\n",
    "        if verbose and i % 10 == 0:\n",
    "            print(f\"[{i}] Processing {row.get('sid')} @ {row.get('time_stamp')}\")\n",
    "\n",
    "        try:\n",
    "            path = fetch_era5_for_row(row)\n",
    "\n",
    "            if path is None:\n",
    "                if not drop_failed:\n",
    "                    enriched_rows.append(pd.DataFrame([row]))\n",
    "                continue\n",
    "\n",
    "            with xr.open_dataset(path) as ds_era5:\n",
    "                features = extract_era5_at_point(\n",
    "                    ds_era5,\n",
    "                    row[\"lat\"],\n",
    "                    row[\"lon\"]\n",
    "                )\n",
    "\n",
    "            Path(path).unlink(missing_ok=True)\n",
    "\n",
    "            df_row = build_enriched_row(row, features)\n",
    "            enriched_rows.append(df_row)\n",
    "\n",
    "        except Exception as e:\n",
    "            if verbose:\n",
    "                print(f\"Failed for row {i}: {e}\")\n",
    "\n",
    "            if not drop_failed:\n",
    "                enriched_rows.append(pd.DataFrame([row]))\n",
    "\n",
    "            if throttle_seconds > 0:\n",
    "                time.sleep(throttle_seconds)\n",
    "\n",
    "    if len(enriched_rows) == 0:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    return pd.concat(enriched_rows, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736b1477",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_era5_ready = df[df[\"time_stamp\"] <= \"2025-12-10 22:00\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7cdff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_era5 = enrich_ibtracs_with_era5(\n",
    "    df_era5_ready,\n",
    "    max_rows=2,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "df_era5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd8b188",
   "metadata": {},
   "source": [
    "### time series track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5e558c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import cdsapi\n",
    "\n",
    "# =========================================================\n",
    "# CONFIG GLOBALE\n",
    "# =========================================================\n",
    "\n",
    "ERA5_OUT = Path(\"data/era5_tests\")\n",
    "ERA5_OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "VARIABLES = [\n",
    "    \"10m_u_component_of_wind\",\n",
    "    \"10m_v_component_of_wind\",\n",
    "    \"2m_temperature\",\n",
    "    \"mean_sea_level_pressure\",\n",
    "]\n",
    "\n",
    "ERA5_VAR_MAP = {\n",
    "    \"10m_u_component_of_wind\": \"u10\",\n",
    "    \"10m_v_component_of_wind\": \"v10\",\n",
    "    \"2m_temperature\": \"t2m\",\n",
    "    \"mean_sea_level_pressure\": \"msl\",\n",
    "}\n",
    "\n",
    "GRID = (0.5, 0.5)      # résolution ERA5\n",
    "BBOX_PAD = 2.0         # marge spatiale (degrés)\n",
    "\n",
    "# =========================================================\n",
    "# OUTILS DE BASE\n",
    "# =========================================================\n",
    "\n",
    "def normalize_lon_0_360(lon):\n",
    "    lon = np.asarray(lon, dtype=float)\n",
    "    return np.mod(lon, 360.0)\n",
    "\n",
    "def compute_bbox(df, pad=BBOX_PAD):\n",
    "    lat_min = float(df[\"lat\"].min()) - pad\n",
    "    lat_max = float(df[\"lat\"].max()) + pad\n",
    "\n",
    "    lon = normalize_lon_0_360(df[\"lon\"].values)\n",
    "    lon_min = float(lon.min()) - pad\n",
    "    lon_max = float(lon.max()) + pad\n",
    "\n",
    "    return [\n",
    "        float(min(90.0, lat_max)),\n",
    "        float(max(0.0, lon_min)),\n",
    "        float(max(-90.0, lat_min)),\n",
    "        float(min(360.0, lon_max)),\n",
    "    ]  # [N, W, S, E]\n",
    "\n",
    "def cds_day_list(days):\n",
    "    return [f\"{int(d):02d}\" for d in sorted(set(days))]\n",
    "\n",
    "def cds_time_list(hours):\n",
    "    return [f\"{int(h):02d}:00\" for h in sorted(set(hours))]\n",
    "\n",
    "# =========================================================\n",
    "# ERA5 DOWNLOAD\n",
    "# =========================================================\n",
    "\n",
    "def download_era5(area, year, month, days, hours, out_nc, force=False):\n",
    "    if out_nc.exists() and not force:\n",
    "        return out_nc\n",
    "\n",
    "    c = cdsapi.Client()\n",
    "    req = {\n",
    "        \"product_type\": \"reanalysis\",\n",
    "        \"variable\": VARIABLES,\n",
    "        \"year\": str(year),\n",
    "        \"month\": f\"{month:02d}\",\n",
    "        \"day\": cds_day_list(days),\n",
    "        \"time\": cds_time_list(hours),\n",
    "        \"area\": area,\n",
    "        \"grid\": [GRID[0], GRID[1]],\n",
    "        \"data_format\": \"netcdf\",\n",
    "    }\n",
    "\n",
    "    print(f\"[ERA5] download {year}-{month:02d}\")\n",
    "    c.retrieve(\"reanalysis-era5-single-levels\", req, str(out_nc))\n",
    "    return out_nc\n",
    "\n",
    "# =========================================================\n",
    "# SAMPLING ERA5 -> IBTrACS\n",
    "# =========================================================\n",
    "\n",
    "def sample_era5_to_obs(nc_path, df):\n",
    "    ds = xr.open_dataset(nc_path)\n",
    "    time_dim = \"time\" if \"time\" in ds.dims else \"valid_time\"\n",
    "\n",
    "    df = df.copy()\n",
    "    df[\"lon_0360\"] = normalize_lon_0_360(df[\"lon\"].values)\n",
    "\n",
    "    p_time = xr.DataArray(df[\"time_stamp\"].values, dims=\"point\")\n",
    "    p_lat = xr.DataArray(df[\"lat\"].values, dims=\"point\")\n",
    "    p_lon = xr.DataArray(df[\"lon_0360\"].values, dims=\"point\")\n",
    "\n",
    "    ds_t = ds.sel({time_dim: p_time}, method=\"nearest\")\n",
    "    ds_p = ds_t.sel(latitude=p_lat, longitude=p_lon, method=\"nearest\")\n",
    "\n",
    "    era_vars_nc = [ERA5_VAR_MAP[v] for v in VARIABLES]\n",
    "    era_df = ds_p[era_vars_nc].to_dataframe().reset_index(drop=True)\n",
    "    era_df = era_df.rename(columns={v_nc: v for v, v_nc in ERA5_VAR_MAP.items()})\n",
    "\n",
    "    return pd.concat([df.reset_index(drop=True), era_df], axis=1)\n",
    "\n",
    "# =========================================================\n",
    "# SUBSETS CONTRÔLÉS\n",
    "# =========================================================\n",
    "\n",
    "def subset_n_cyclones(df, n=100, seed=0):\n",
    "    sids = (\n",
    "        df.groupby(\"sid\")\n",
    "          .size()\n",
    "          .sort_values(ascending=False)\n",
    "          .head(n)\n",
    "          .index\n",
    "    )\n",
    "    return df[df[\"sid\"].isin(sids)].copy()\n",
    "\n",
    "def subset_month(df, year, month):\n",
    "    ts = pd.to_datetime(df[\"time_stamp\"])\n",
    "    return df[(ts.dt.year == year) & (ts.dt.month == month)].copy()\n",
    "\n",
    "# =========================================================\n",
    "# RUNNER DE TEST\n",
    "# =========================================================\n",
    "\n",
    "def run_controlled_test(df, label=\"test\", force_download=False):\n",
    "    df = df.copy()\n",
    "    df[\"time_stamp\"] = pd.to_datetime(df[\"time_stamp\"])\n",
    "\n",
    "    df[\"year\"] = df[\"time_stamp\"].dt.year\n",
    "    df[\"month\"] = df[\"time_stamp\"].dt.month\n",
    "    df[\"day\"] = df[\"time_stamp\"].dt.day\n",
    "    df[\"hour\"] = df[\"time_stamp\"].dt.hour\n",
    "\n",
    "    year = int(df[\"year\"].iloc[0])\n",
    "    month = int(df[\"month\"].iloc[0])\n",
    "    df = df[(df[\"year\"] == year) & (df[\"month\"] == month)].copy()\n",
    "\n",
    "    area = compute_bbox(df)\n",
    "    days = df[\"day\"].unique()\n",
    "    hours = df[\"hour\"].unique()\n",
    "\n",
    "    out_nc = ERA5_OUT / f\"era5_{label}_{year}_{month:02d}.nc\"\n",
    "\n",
    "    print(\"\\n====================================\")\n",
    "    print(f\"TEST [{label}]\")\n",
    "    print(\"rows:\", len(df))\n",
    "    print(\"cyclones:\", df['sid'].nunique())\n",
    "    print(\"month:\", f\"{year}-{month:02d}\")\n",
    "    print(\"bbox:\", area)\n",
    "    print(\"====================================\")\n",
    "\n",
    "    t0 = time.perf_counter()\n",
    "    download_era5(area, year, month, days, hours, out_nc, force=force_download)\n",
    "    t1 = time.perf_counter()\n",
    "\n",
    "    size_mb = out_nc.stat().st_size / (1024**2)\n",
    "    print(f\"download: {t1-t0:.2f}s | file: {size_mb:.1f} MB\")\n",
    "\n",
    "    merged = sample_era5_to_obs(out_nc, df)\n",
    "    t2 = time.perf_counter()\n",
    "    print(f\"sample+merge: {t2-t1:.2f}s\")\n",
    "\n",
    "    nan_rate = merged[VARIABLES].isna().mean()\n",
    "    print(\"NaN rates:\")\n",
    "    print(nan_rate)\n",
    "\n",
    "    return merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42c8b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = subset_n_cyclones(df_filtered, n=20)\n",
    "m1 = run_controlled_test(df_test, label=\"n20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95864a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29cbf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_recent_years(\n",
    "    df,\n",
    "    start_year=2015,\n",
    "    end_year=2025,\n",
    "    n_cyclones_per_month=20,\n",
    "    force_download=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Augmente le dataset IBTrACS avec ERA5 sur les années récentes,\n",
    "    en contrôlant le nombre de cyclones par mois.\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.copy()\n",
    "    df[\"time_stamp\"] = pd.to_datetime(df[\"time_stamp\"])\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # boucle années / mois\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        for month in range(1, 13):\n",
    "\n",
    "            df_month = df[\n",
    "                (df[\"time_stamp\"].dt.year == year) &\n",
    "                (df[\"time_stamp\"].dt.month == month)\n",
    "            ]\n",
    "\n",
    "            if df_month.empty:\n",
    "                continue\n",
    "\n",
    "            # sélection des N cyclones les plus riches DU MOIS\n",
    "            df_month = subset_n_cyclones(\n",
    "                df_month,\n",
    "                n=n_cyclones_per_month\n",
    "            )\n",
    "\n",
    "            label = f\"y{year}_m{month:02d}_n{n_cyclones_per_month}\"\n",
    "\n",
    "            try:\n",
    "                merged = run_controlled_test(\n",
    "                    df_month,\n",
    "                    label=label,\n",
    "                    force_download=force_download\n",
    "                )\n",
    "                results.append(merged)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"[SKIP] {label} → {e}\")\n",
    "                continue\n",
    "\n",
    "    if not results:\n",
    "        raise RuntimeError(\"Aucune donnée produite.\")\n",
    "\n",
    "    return pd.concat(results, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd828568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN TEST on monthly API calls\n",
    "\n",
    "df_aug = augment_recent_years(\n",
    "    df_filtered,\n",
    "    start_year=2020,\n",
    "    end_year=2022,\n",
    "    n_cyclones_per_month=15\n",
    ")\n",
    "\n",
    "df_aug.to_parquet(\"data/ibtracs_era5_augmented_recent.parquet\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa704f94",
   "metadata": {},
   "source": [
    "### Yearly API call test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935ba04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "ERA5_OUT = Path(\"data/era5_yearly_tests\")\n",
    "ERA5_OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "VARIABLES = [\n",
    "    \"10m_u_component_of_wind\",\n",
    "    \"10m_v_component_of_wind\",\n",
    "    \"2m_temperature\",\n",
    "    \"mean_sea_level_pressure\",\n",
    "]\n",
    "\n",
    "ERA5_VAR_MAP = {\n",
    "    \"10m_u_component_of_wind\": \"u10\",\n",
    "    \"10m_v_component_of_wind\": \"v10\",\n",
    "    \"2m_temperature\": \"t2m\",\n",
    "    \"mean_sea_level_pressure\": \"msl\",\n",
    "}\n",
    "\n",
    "GRID = (0.5, 0.5)      # résolution ERA5\n",
    "BBOX_PAD = 2.0         # marge spatiale (degrés)\n",
    "\n",
    "def normalize_lon_0_360(lon):\n",
    "    lon = np.asarray(lon, dtype=float)\n",
    "    return np.mod(lon, 360.0)\n",
    "\n",
    "def compute_bbox(df, pad=BBOX_PAD):\n",
    "    lat_min = float(df[\"lat\"].min()) - pad\n",
    "    lat_max = float(df[\"lat\"].max()) + pad\n",
    "\n",
    "    lon = normalize_lon_0_360(df[\"lon\"].values)\n",
    "    lon_min = float(lon.min()) - pad\n",
    "    lon_max = float(lon.max()) + pad\n",
    "\n",
    "    return [\n",
    "        float(min(90.0, lat_max)),\n",
    "        float(max(0.0, lon_min)),\n",
    "        float(max(-90.0, lat_min)),\n",
    "        float(min(360.0, lon_max)),\n",
    "    ]  # [N, W, S, E]\n",
    "\n",
    "def cds_day_list(days):\n",
    "    return [f\"{int(d):02d}\" for d in sorted(set(days))]\n",
    "\n",
    "def cds_time_list(hours):\n",
    "    return [f\"{int(h):02d}:00\" for h in sorted(set(hours))]\n",
    "\n",
    "def subset_top_cyclones_per_year(df, year, n=50):\n",
    "    df_y = df[df[\"time_stamp\"].dt.year == year].copy()\n",
    "\n",
    "    sids = (\n",
    "        df_y.groupby(\"sid\")\n",
    "            .size()\n",
    "            .sort_values(ascending=False)\n",
    "            .head(n)\n",
    "            .index\n",
    "    )\n",
    "\n",
    "    return df_y[df_y[\"sid\"].isin(sids)].copy()\n",
    "\n",
    "def sample_era5_to_obs(nc_path, df):\n",
    "    ds = xr.open_dataset(nc_path)\n",
    "    time_dim = \"time\" if \"time\" in ds.dims else \"valid_time\"\n",
    "\n",
    "    df = df.copy()\n",
    "    df[\"lon_0360\"] = normalize_lon_0_360(df[\"lon\"].values)\n",
    "\n",
    "    p_time = xr.DataArray(df[\"time_stamp\"].values, dims=\"point\")\n",
    "    p_lat = xr.DataArray(df[\"lat\"].values, dims=\"point\")\n",
    "    p_lon = xr.DataArray(df[\"lon_0360\"].values, dims=\"point\")\n",
    "\n",
    "    ds_t = ds.sel({time_dim: p_time}, method=\"nearest\")\n",
    "    ds_p = ds_t.sel(latitude=p_lat, longitude=p_lon, method=\"nearest\")\n",
    "\n",
    "    era_vars_nc = [ERA5_VAR_MAP[v] for v in VARIABLES]\n",
    "    era_df = ds_p[era_vars_nc].to_dataframe().reset_index(drop=True)\n",
    "    era_df = era_df.rename(columns={v_nc: v for v, v_nc in ERA5_VAR_MAP.items()})\n",
    "\n",
    "    return pd.concat([df.reset_index(drop=True), era_df], axis=1)\n",
    "\n",
    "def run_yearly_test(\n",
    "    df,\n",
    "    year,\n",
    "    n_cyclones=50,\n",
    "    label=None,\n",
    "    force_download=False,\n",
    "):\n",
    "    df = df.copy()\n",
    "    df[\"time_stamp\"] = pd.to_datetime(df[\"time_stamp\"])\n",
    "\n",
    "    df_y = subset_top_cyclones_per_year(df, year, n=n_cyclones)\n",
    "\n",
    "    if df_y.empty:\n",
    "        raise ValueError(f\"Aucune donnée pour {year}\")\n",
    "\n",
    "    df_y[\"day\"] = df_y[\"time_stamp\"].dt.day\n",
    "    df_y[\"month\"] = df_y[\"time_stamp\"].dt.month\n",
    "    df_y[\"hour\"] = df_y[\"time_stamp\"].dt.hour\n",
    "\n",
    "    area = compute_bbox(df_y)\n",
    "    days = df_y[\"day\"].unique()\n",
    "    hours = df_y[\"hour\"].unique()\n",
    "    months = df_y[\"month\"].unique()\n",
    "\n",
    "    label = label or f\"year{year}_n{n_cyclones}\"\n",
    "    out_nc = ERA5_OUT / f\"era5_{label}.nc\"\n",
    "\n",
    "    print(\"\\n====================================\")\n",
    "    print(f\"YEAR TEST [{year}]\")\n",
    "    print(\"cyclones:\", df_y[\"sid\"].nunique())\n",
    "    print(\"rows:\", len(df_y))\n",
    "    print(\"bbox:\", area)\n",
    "    print(\"====================================\")\n",
    "\n",
    "    t0 = time.perf_counter()\n",
    "\n",
    "    c = cdsapi.Client()\n",
    "    req = {\n",
    "        \"product_type\": \"reanalysis\",\n",
    "        \"variable\": VARIABLES,\n",
    "        \"year\": str(year),\n",
    "        \"month\": [f\"{m:02d}\" for m in sorted(months)],\n",
    "        \"day\": cds_day_list(days),\n",
    "        \"time\": cds_time_list(hours),\n",
    "        \"area\": area,\n",
    "        \"grid\": [GRID[0], GRID[1]],\n",
    "        \"data_format\": \"netcdf\",\n",
    "    }\n",
    "\n",
    "    if not out_nc.exists() or force_download:\n",
    "        c.retrieve(\"reanalysis-era5-single-levels\", req, str(out_nc))\n",
    "\n",
    "    t1 = time.perf_counter()\n",
    "    print(f\"download: {t1 - t0:.2f}s | file: {out_nc.stat().st_size / 1e6:.1f} MB\")\n",
    "\n",
    "    merged = sample_era5_to_obs(out_nc, df_y)\n",
    "    print(\"merge OK\")\n",
    "\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c62632e",
   "metadata": {},
   "source": [
    "### 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96a4601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 18 mn pour 1gb de données, 2022, et 3 cyclones\n",
    "\n",
    "df_2022 = run_yearly_test(\n",
    "    df_filtered,\n",
    "    year=2022,\n",
    "    n_cyclones=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa67ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROCESSED_DIR = Path(\"data/processed\")\n",
    "PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "out_path = PROCESSED_DIR / \"ibtracs_era5_2022.csv\"\n",
    "\n",
    "df_2022.to_csv(out_path, index=False)\n",
    "\n",
    "print(f\"Saved to {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511eab2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_2022.shape)\n",
    "print(df_2022.columns)\n",
    "\n",
    "print(\"Cyclones:\", df_2022[\"sid\"].nunique())\n",
    "print(\"Période:\",\n",
    "      df_2022[\"time_stamp\"].min(),\n",
    "      \"→\",\n",
    "      df_2022[\"time_stamp\"].max())\n",
    "\n",
    "df_2022.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba830309",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2022[[\n",
    "    \"10m_u_component_of_wind\",\n",
    "    \"10m_v_component_of_wind\",\n",
    "    \"2m_temperature\",\n",
    "    \"mean_sea_level_pressure\"\n",
    "]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4128451d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "for sid, g in df_2022.groupby(\"sid\"):\n",
    "    plt.plot(g[\"lon\"], g[\"lat\"], marker=\"o\", label=sid)\n",
    "\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "plt.title(\"Trajectoires des cyclones (2022)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c5a126",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for sid, g in df_2022.groupby(\"sid\"):\n",
    "    g = g.sort_values(\"time_stamp\")\n",
    "    plt.plot(\n",
    "        g[\"time_stamp\"],\n",
    "        g[\"mean_sea_level_pressure\"],\n",
    "        label=sid\n",
    "    )\n",
    "\n",
    "plt.xlabel(\"Temps\")\n",
    "plt.ylabel(\"Pression niveau mer (Pa)\")\n",
    "plt.title(\"Évolution de la pression ERA5\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b840b40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(\n",
    "    df_2022[\"2m_temperature\"],\n",
    "    df_2022[\"mean_sea_level_pressure\"],\n",
    "    alpha=0.6\n",
    ")\n",
    "plt.xlabel(\"Température 2m (K)\")\n",
    "plt.ylabel(\"Pression niveau mer (Pa)\")\n",
    "plt.title(\"Température vs Pression\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5993903",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2022.isna().mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f5e746",
   "metadata": {},
   "source": [
    "The merged IBTrACS–ERA5 dataset for 2022 shows strong internal consistency and physically plausible behavior. The selected cyclones exhibit coherent trajectories across distinct ocean basins, with smooth spatial evolution and no discontinuities. ERA5 sea-level pressure fields capture the expected cyclone signatures, with pressure minima temporally aligned with the most intense phases of each system. The relationship between near-surface temperature and pressure follows realistic meteorological patterns, with lower pressures generally associated with warmer air masses. No missing values were observed in the merged ERA5 variables, confirming the robustness of the spatial–temporal sampling strategy and the validity of the data integration pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2892c68c",
   "metadata": {},
   "source": [
    "### 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44e53d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2023 = run_yearly_test(\n",
    "    df_filtered,\n",
    "    year=2023,\n",
    "    n_cyclones=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f7aa98",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = PROCESSED_DIR / \"ibtracs_era5_2023.csv\"\n",
    "\n",
    "df_2023.to_csv(out_path, index=False)\n",
    "\n",
    "print(f\"Saved to {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd70388",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "df_plot = df_2023.sort_values(\"time_stamp\")\n",
    "\n",
    "fig = px.line_geo(\n",
    "    df_plot,\n",
    "    lon=\"lon\",\n",
    "    lat=\"lat\",\n",
    "    color=\"sid\",\n",
    "    hover_name=\"name\",\n",
    "    hover_data={\n",
    "        \"time_stamp\": True,\n",
    "        \"wind\": True,\n",
    "        \"pressure\": True,\n",
    "        \"mean_sea_level_pressure\": True,\n",
    "    },\n",
    "    title=\"Cyclone trajectories (2022)\",\n",
    ")\n",
    "\n",
    "fig.update_traces(\n",
    "    mode=\"lines+markers\",\n",
    "    marker=dict(size=5),\n",
    "    line=dict(width=2),\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    geo=dict(\n",
    "        projection_type=\"natural earth\",\n",
    "        showland=True,\n",
    "        landcolor=\"rgb(230, 230, 230)\",\n",
    "        showcountries=True,\n",
    "        showocean=True,\n",
    "        oceancolor=\"rgb(200, 220, 255)\",\n",
    "    ),\n",
    "    legend_title_text=\"Cyclone SID\",\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
