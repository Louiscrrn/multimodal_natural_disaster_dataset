{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc17b64c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Merged dataset saved\n",
      "Path: ../data/processed/ibtracs_era5_2024.csv\n",
      "Shape: (1308, 26)\n",
      "Cyclones: 32\n",
      "Basins: ['NI', 'SI', 'SP']\n",
      "Period: 2024-01-01 00:00:00.000039936 → 2024-12-31 00:00:00.000039936\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Dossier des fichiers traités\n",
    "PROCESSED_DIR = Path(\"../../data/processed\")\n",
    "\n",
    "# Fichiers à merger\n",
    "paths = [\n",
    "    PROCESSED_DIR / \"ibtracs_era5_2024.csv\",\n",
    "    PROCESSED_DIR / \"ibtracs_era5_2024_SP.csv\",\n",
    "]\n",
    "\n",
    "# Chargement\n",
    "dfs = []\n",
    "for p in paths:\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(f\"Missing file: {p}\")\n",
    "    dfs.append(pd.read_csv(p, parse_dates=[\"time_stamp\"]))\n",
    "\n",
    "# Merge vertical\n",
    "df_2024 = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Optionnel : tri temporel\n",
    "df_2024 = df_2024.sort_values(\"time_stamp\").reset_index(drop=True)\n",
    "\n",
    "# Sauvegarde finale\n",
    "out_path = PROCESSED_DIR / \"ibtracs_era5_2024.csv\"\n",
    "df_2024.to_csv(out_path, index=False)\n",
    "\n",
    "# Sanity checks\n",
    "print(\"[OK] Merged dataset saved\")\n",
    "print(\"Path:\", out_path)\n",
    "print(\"Shape:\", df_2024.shape)\n",
    "print(\"Cyclones:\", df_2024[\"sid\"].nunique())\n",
    "print(\"Basins:\", sorted(df_2024[\"basin\"].unique()))\n",
    "print(\n",
    "    \"Period:\",\n",
    "    df_2024[\"time_stamp\"].min(),\n",
    "    \"→\",\n",
    "    df_2024[\"time_stamp\"].max(),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39cdff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Période retenue: 2024 → 2024 | obs: 4465 | cyclones: 94 | basins: ['EP', 'NA', 'NI', 'SI', 'SP', 'WP']\n",
      "IBTrACS 2024:\n",
      "obs: 4465\n",
      "cyclones: 94\n",
      "basins: ['EP', 'NA', 'NI', 'SI', 'SP', 'WP']\n",
      "\n",
      "=== Basin EP ===\n",
      "obs: 703\n",
      "cyclones: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling ERA5: 100%|██████████| 481/481 [00:01<00:00, 433.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Basin NI ===\n",
      "obs: 219\n",
      "cyclones: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling ERA5: 100%|██████████| 219/219 [00:00<00:00, 477.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Basin SI ===\n",
      "obs: 876\n",
      "cyclones: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling ERA5: 100%|██████████| 735/735 [00:01<00:00, 447.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Basin SP ===\n",
      "obs: 213\n",
      "cyclones: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling ERA5: 100%|██████████| 186/186 [00:00<00:00, 466.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[OK] Final dataset saved\n",
      "Path: ../data/processed/ibtracs_era5_2024.csv\n",
      "Shape: (2011, 26)\n",
      "Cyclones: 47\n",
      "Basins: ['EP', 'NI', 'SI', 'SP']\n",
      "Period: 2024-01-01 00:00:00.000039936 → 2024-12-31 00:00:00.000039936\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from building_era5 import load_IBTrACS, clean_basin, sample_era5_year_fast\n",
    "\n",
    "# -----------------------\n",
    "# Paths\n",
    "# -----------------------\n",
    "ERA5_DIR = Path(\"../../data/era5_yearly_tests\")\n",
    "PROCESSED_DIR = Path(\"../data/processed\")\n",
    "PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "IBTRACS_PATH = PROCESSED_DIR / \"ibtracs_usa_processed_20251216_164245.csv\"\n",
    "OUT_PATH = PROCESSED_DIR / \"ibtracs_era5_2024.csv\"\n",
    "\n",
    "# -----------------------\n",
    "# ERA5 files per basin\n",
    "# -----------------------\n",
    "era5_files = {\n",
    "    \"EP\": ERA5_DIR / \"era5_year2024_EP_n3.nc\",\n",
    "    \"NI\": ERA5_DIR / \"era5_year2024_NI_n3.nc\",\n",
    "    \"SI\": ERA5_DIR / \"era5_year2024_SI_n3.nc\",\n",
    "    \"SP\": ERA5_DIR / \"era5_year2024_SP_n3.nc\",\n",
    "}\n",
    "\n",
    "# -----------------------\n",
    "# Load IBTrACS\n",
    "# -----------------------\n",
    "df_ib = load_IBTrACS(IBTRACS_PATH, years=[2024, 2024])\n",
    "df_ib[\"basin\"] = df_ib[\"basin\"].apply(clean_basin)\n",
    "\n",
    "print(\"IBTrACS 2024:\")\n",
    "print(\"obs:\", len(df_ib))\n",
    "print(\"cyclones:\", df_ib[\"sid\"].nunique())\n",
    "print(\"basins:\", sorted(df_ib[\"basin\"].unique()))\n",
    "\n",
    "# -----------------------\n",
    "# Sampling per basin\n",
    "# -----------------------\n",
    "merged_all = []\n",
    "\n",
    "for basin, nc_path in era5_files.items():\n",
    "    print(f\"\\n=== Basin {basin} ===\")\n",
    "\n",
    "    if not nc_path.exists():\n",
    "        print(\"ERA5 file missing → skipped\")\n",
    "        continue\n",
    "\n",
    "    df_basin = df_ib[df_ib[\"basin\"] == basin].copy()\n",
    "    if df_basin.empty:\n",
    "        print(\"No IBTrACS data → skipped\")\n",
    "        continue\n",
    "\n",
    "    print(\"obs:\", len(df_basin))\n",
    "    print(\"cyclones:\", df_basin[\"sid\"].nunique())\n",
    "\n",
    "    df_merged = sample_era5_year_fast(nc_path, df_basin)\n",
    "    merged_all.append(df_merged)\n",
    "\n",
    "# -----------------------\n",
    "# Final merge + save\n",
    "# -----------------------\n",
    "if not merged_all:\n",
    "    raise RuntimeError(\"No basin produced data\")\n",
    "\n",
    "df_2024 = (\n",
    "    pd.concat(merged_all, ignore_index=True)\n",
    "      .sort_values(\"time_stamp\")\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "df_2024.to_csv(OUT_PATH, index=False)\n",
    "\n",
    "# -----------------------\n",
    "# Sanity checks\n",
    "# -----------------------\n",
    "print(\"\\n[OK] Final dataset saved\")\n",
    "print(\"Path:\", OUT_PATH)\n",
    "print(\"Shape:\", df_2024.shape)\n",
    "print(\"Cyclones:\", df_2024[\"sid\"].nunique())\n",
    "print(\"Basins:\", sorted(df_2024[\"basin\"].unique()))\n",
    "print(\n",
    "    \"Period:\",\n",
    "    df_2024[\"time_stamp\"].min(),\n",
    "    \"→\",\n",
    "    df_2024[\"time_stamp\"].max(),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46c1e4e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ibtracs_era5_2022.csv\n",
      "Loading ibtracs_era5_2023.csv\n",
      "Loading ibtracs_era5_2024.csv\n",
      "\n",
      "=== Dataset summary ===\n",
      "Rows: 12911\n",
      "Cyclones: 230\n",
      "Years: [np.int32(2022), np.int32(2023), np.int32(2024)]\n",
      "\n",
      "[OK] Merged dataset saved to: ../../data/processed/ibtracs_era5_20251216.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Paths\n",
    "# -------------------------------------------------\n",
    "DATA_DIR = Path(\"../../data/processed\")\n",
    "\n",
    "files = [\n",
    "    DATA_DIR / \"ibtracs_era5_2022.csv\",\n",
    "    DATA_DIR / \"ibtracs_era5_2023.csv\",\n",
    "    DATA_DIR / \"ibtracs_era5_2024.csv\",\n",
    "]\n",
    "\n",
    "today = datetime.today().strftime(\"%Y%m%d\")\n",
    "out_path = DATA_DIR / f\"ibtracs_era5_{today}.csv\"\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Load & concatenate\n",
    "# -------------------------------------------------\n",
    "dfs = []\n",
    "\n",
    "for f in files:\n",
    "    print(f\"Loading {f.name}\")\n",
    "    df = pd.read_csv(f, parse_dates=[\"time_stamp\"])\n",
    "    dfs.append(df)\n",
    "\n",
    "df_all = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Basic sanity checks\n",
    "# -------------------------------------------------\n",
    "print(\"\\n=== Dataset summary ===\")\n",
    "print(\"Rows:\", len(df_all))\n",
    "print(\"Cyclones:\", df_all[\"sid\"].nunique())\n",
    "print(\"Years:\", sorted(df_all[\"time_stamp\"].dt.year.unique()))\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Sort & save\n",
    "# -------------------------------------------------\n",
    "df_all = df_all.sort_values(\"time_stamp\")\n",
    "\n",
    "df_all.to_csv(out_path, index=False)\n",
    "\n",
    "print(f\"\\n[OK] Merged dataset saved to: {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8692bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
